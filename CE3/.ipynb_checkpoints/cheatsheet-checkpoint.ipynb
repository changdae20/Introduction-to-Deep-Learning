{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Basic : Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape :  [32 10 10  3]  filter shape :  [2 2 3 5]  output shape :  [32 10 10  5]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataset = tfds.load('cifar100')\n",
    "trainset, testset = dataset['train'], dataset['test']\n",
    "\n",
    "# create variables\n",
    "var1 = tf.Variable([1.0, 2.0])\n",
    "var2 = tf.Variable(tf.random.truncated_normal(shape=[2], mean=0.0, stddev=1.0,))\n",
    "\n",
    "# convolution operation\n",
    "fltr_height, fltr_weight, in_channels, out_channels = 2, 2, 3, 5\n",
    "fltr = tf.Variable(tf.random.truncated_normal(shape=[fltr_height, fltr_weight, in_channels, out_channels]))\n",
    "batch_size, img_height, img_weight, img_channels = 32, 10, 10, 3\n",
    "ipts = np.random.rand(batch_size, img_height, img_weight, img_channels)\n",
    "opts = tf.nn.conv2d(ipts, filters=fltr, padding='SAME', strides=1)\n",
    "\n",
    "# print\n",
    "print('input shape : ', tf.shape(ipts).numpy(), ' filter shape : ', tf.shape(fltr).numpy(), ' output shape : ', tf.shape(opts).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Module : Container for variables and other modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyModule.trainable_variables\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "DummyModule.submodules\n",
      "[3, 4]\n",
      "[5, 6]\n"
     ]
    }
   ],
   "source": [
    "class SubModule(tf.Module):\n",
    "    def __init__(self, val1, val2):\n",
    "        self.var1 = tf.Variable(val1)\n",
    "        self.var2 = tf.Variable(val2)\n",
    "        \n",
    "class DummyModule(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.var1 = tf.Variable(1)\n",
    "        self.var2 = tf.Variable(2)\n",
    "        self.sub1 = SubModule(3, 4)\n",
    "        self.sub2 = SubModule(5, 6)\n",
    "        return\n",
    "    \n",
    "model = DummyModule()\n",
    "print('DummyModule.trainable_variables')\n",
    "for var in model.trainable_variables:\n",
    "    print(var.numpy())\n",
    "\n",
    "print('DummyModule.submodules')\n",
    "for submodule in model.submodules:\n",
    "    print([var.numpy() for var in submodule.trainable_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas\n",
    "datanum, iptdim, optdim = 10, 3, 2\n",
    "x, y = np.random.rand(datanum, iptdim), np.random.rand(datanum, optdim)\n",
    "\n",
    "# variables \n",
    "w = tf.Variable(tf.random.normal(shape=[iptdim, optdim], dtype=tf.float64))\n",
    "b = tf.Variable(tf.random.normal(shape=[optdim], dtype=tf.float64))\n",
    "variables = [w, b]\n",
    "\n",
    "# calculate derivative\n",
    "with tf.GradientTape() as tape:\n",
    "    pred = tf.matmul(x, w) + b\n",
    "    loss = tf.reduce_mean(tf.reduce_sum((y - pred) ** 2, axis=1))\n",
    "gradients = tape.gradient(loss, variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-1.0000000000000002, shape=(), dtype=float64)\n",
      "tf.Tensor(-1.0000000000000002, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# apply gradient\n",
    "original_variables = [var.numpy() for var in variables]\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
    "optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "# check direction\n",
    "for idx in range(len(gradients)):\n",
    "    grad, var = gradients[idx], variables[idx]\n",
    "    diff = var - original_variables[idx]\n",
    "    dot = tf.reduce_sum(grad * diff)\n",
    "    norm = tf.norm(grad) * tf.norm(diff)\n",
    "    print(dot / norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model : Easy way to build and train deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [2.4250874519348145, 2.347337007522583, 2.394089698791504, 2.566899061203003, 2.3855929374694824]}\n"
     ]
    }
   ],
   "source": [
    "# datas\n",
    "clsnum = 10\n",
    "datanum = 10\n",
    "ipt_shape = [10, 10, 3]\n",
    "x, y = np.random.rand(datanum, *ipt_shape), np.random.randint(high=clsnum, low=0, size=datanum)\n",
    "\n",
    "# model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=7,\n",
    "        kernel_size=[2, 2],\n",
    "        strides=1,\n",
    "        padding='SAME'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'), \n",
    "    tf.keras.layers.Dropout(rate=0.2), \n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=clsnum,\n",
    "        kernel_size=[2, 2],\n",
    "        strides=1,\n",
    "        padding='SAME'),\n",
    "    tf.keras.layers.GlobalMaxPool2D(), \n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "# compile and \n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "\n",
    "# train (fit)\n",
    "history = model.fit(x=x, y=y, epochs=5, verbose=0) # verbose=1 : print training state\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and restore variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before restore 2 2\n",
      "after restore 1 1\n"
     ]
    }
   ],
   "source": [
    "class DummyModule(tf.Module):\n",
    "    def __init__(self, val):\n",
    "        self.var = tf.Variable(val)\n",
    "        \n",
    "# save\n",
    "v1 = tf.Variable(1)\n",
    "m1 = DummyModule(1)\n",
    "ckpt_map1 = {'var' : v1, 'model' : m1}\n",
    "ckpt1 = tf.train.Checkpoint(**ckpt_map1)\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint=ckpt1, directory='ckpt', max_to_keep=1)\n",
    "ckpt_manager.save()\n",
    "\n",
    "# make other variables\n",
    "v2 = tf.Variable(2)\n",
    "m2 = DummyModule(2)\n",
    "print('before restore', v2.numpy(), m2.var.numpy())\n",
    "\n",
    "# restore\n",
    "ckpt_map2 = {'var' : v2, 'model' : m2}\n",
    "ckpt2 = tf.train.Checkpoint(**ckpt_map2)\n",
    "ckpt2.restore(ckpt_manager.latest_checkpoint)\n",
    "print('after restore', v2.numpy(), m2.var.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save variables and operation graph of model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: testestse/assets\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = 'saved_model'\n",
    "datacnt, iptdim, optdim = 32, 5, 3\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(optdim, input_shape=[None, iptdim]))\n",
    "\n",
    "# compile\n",
    "model.compile()\n",
    "\n",
    "# save model\n",
    "model.save(MODEL_PATH)\n",
    "\n",
    "# load model\n",
    "loaded = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "# compare\n",
    "x = np.random.rand(datacnt, iptdim)\n",
    "print(tf.reduce_sum(tf.abs(loaded(x) - model(x))).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
