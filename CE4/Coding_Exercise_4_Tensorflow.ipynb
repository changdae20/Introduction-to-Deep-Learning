{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Introduction to Deep Learning Coding Ex 4: Spam Message Generator!\n",
    "\n",
    "Contact T/A: Yeon-goon Kim, SNU ECE, CML. (ygoonkim@cml.snu.ac.kr)  \n",
    "\n",
    "Dataset from http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/\n",
    "\n",
    "On this homework, you will train spam message generator, which is basic RNN/LSTM/GRU char2char generation model. Of course, your results may not so good, but you can expect some sentence-like results by doing this homework sucessfully.\n",
    "\n",
    "## Now, We'll handle texts, not images. Is there any differences?\n",
    "\n",
    "Of course, there are many differences between processing images and texts. One is that text cannot be expressed directly in matrices or tensors. We know an image can be expressed in Tensor(n_channel, width, height). But how about an text sentence? Can word 'Homework' can be expressed in tensor directly? By what laws? With what shapes? Even if it can, which one is closer to the word, 'Burden', or 'Work'? This is called 'Word Embedding Problem' and be considered as one of the most important problem in Natural Language Process(NLP) resarch. Fortunatly, there are some generalized solution in this problem (though not prefect, anyway) and both Tensorflow and Pytorch give basic APIs that solve this problem automatically. You may use those APIs in this homework. \n",
    "\n",
    "The other one is that text is sequential data. Generally, when processing images, without batch, input is just one image. However in text, input is mostly some or one paragraphs/sentences, which is sequential data of embedded character or words. So, If we want to generate word 'Homework' with start token 'H', 'o' before 'H' and 'o' before 'Homew' should operate different when it gives to input. This is why we use RNN-based model in deep learning when processing text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement-Tensorflow\n",
    "In this homework I recommend that you should use the latest \"anaconda\" stable version of Tensorflow, which is on now(2020-11-05) 2.2.x., but latest version(2.3.x) wouldn't be a serious problem. I'm using python3.7 on grading environment but there are no major changes on python3.6/8 so also will not be a serious problem. \n",
    "There are other required packages to run the code which is 'unidecode'. You can easily install these packages with 'pip install unidecode'.  \n",
    "\n",
    "You can add other packages if you want, but if they are not basically given pkgs in Python/Tensorflow you should contact T/A to check whether you can use them or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Import Packages ##########\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import random\n",
    "import unidecode\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "##################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2020\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "###### On TF2.0, it automatically select whether to use GPU(default) or CPU #####\n",
    "#USE_GPU = True\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "############################# Changeable Parameters #############################\n",
    "SEQ_LENGTH = 200\n",
    "N_ITER = 20000\n",
    "TXT_GEN_PERIOD = 1000\n",
    "LEARNING_RATE = 0.005\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepration (Contact T/A If you wan to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([54, 74,  4,  4,  0, 94, 24, 27, 94, 49, 50, 74,  4,  4,  0, 94, 54,\n",
      "       14, 14, 94, 17, 14, 27, 77, 94, 32, 32, 32, 75, 54, 48, 54, 75, 10,\n",
      "       12, 76, 30, 76, 23, 10, 29,  2,  7,  0,  8,  1,  9,  8,  0, 94, 54,\n",
      "       55, 50, 51, 82, 94, 54, 14, 23, 13, 94, 54, 55, 50, 51, 94, 41, 53,\n",
      "       49, 39, 94, 29, 24, 94,  6,  2,  4,  6,  8, 96, 56, 53, 42, 40, 49,\n",
      "       55, 75, 94, 44, 22, 25, 24, 27, 29, 10, 23, 29, 94, 18, 23, 15, 24,\n",
      "       27, 22, 10, 29, 18, 24, 23, 94, 15, 24, 27, 94,  0,  2, 94, 30, 28,\n",
      "       14, 27, 75, 94, 55, 24, 13, 10, 34, 94, 18, 28, 94, 34, 24, 30, 27,\n",
      "       94, 21, 30, 12, 20, 34, 94, 13, 10, 34, 62, 94,  2, 94, 15, 18, 23,\n",
      "       13, 94, 24, 30, 29, 94, 32, 17, 34, 94, 73, 94, 21, 24, 16, 94, 24,\n",
      "       23, 29, 24, 94, 17, 29, 29, 25, 77, 76, 76, 32, 32, 32, 75, 30, 27,\n",
      "       10, 32, 18, 23, 23, 14, 27, 75, 12, 24, 22, 94, 29])>, <tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([74,  4,  4,  0, 94, 24, 27, 94, 49, 50, 74,  4,  4,  0, 94, 54, 14,\n",
      "       14, 94, 17, 14, 27, 77, 94, 32, 32, 32, 75, 54, 48, 54, 75, 10, 12,\n",
      "       76, 30, 76, 23, 10, 29,  2,  7,  0,  8,  1,  9,  8,  0, 94, 54, 55,\n",
      "       50, 51, 82, 94, 54, 14, 23, 13, 94, 54, 55, 50, 51, 94, 41, 53, 49,\n",
      "       39, 94, 29, 24, 94,  6,  2,  4,  6,  8, 96, 56, 53, 42, 40, 49, 55,\n",
      "       75, 94, 44, 22, 25, 24, 27, 29, 10, 23, 29, 94, 18, 23, 15, 24, 27,\n",
      "       22, 10, 29, 18, 24, 23, 94, 15, 24, 27, 94,  0,  2, 94, 30, 28, 14,\n",
      "       27, 75, 94, 55, 24, 13, 10, 34, 94, 18, 28, 94, 34, 24, 30, 27, 94,\n",
      "       21, 30, 12, 20, 34, 94, 13, 10, 34, 62, 94,  2, 94, 15, 18, 23, 13,\n",
      "       94, 24, 30, 29, 94, 32, 17, 34, 94, 73, 94, 21, 24, 16, 94, 24, 23,\n",
      "       29, 24, 94, 17, 29, 29, 25, 77, 76, 76, 32, 32, 32, 75, 30, 27, 10,\n",
      "       32, 18, 23, 23, 14, 27, 75, 12, 24, 22, 94, 29, 17])>)\n",
      "(<tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([94, 11, 14, 94, 17, 14, 27, 94, 15, 27, 18, 14, 23, 13, 75, 94, 53,\n",
      "       14, 25, 21, 34, 94, 60, 40, 54, 74,  4,  4,  0, 94, 24, 27, 94, 49,\n",
      "       50, 74,  4,  4,  0, 94, 54, 14, 14, 94, 17, 14, 27, 77, 94, 32, 32,\n",
      "       32, 75, 54, 48, 54, 75, 10, 12, 76, 30, 76, 23, 10, 29,  2,  7,  0,\n",
      "        8,  1,  9,  8,  0, 94, 54, 55, 50, 51, 82, 94, 54, 14, 23, 13, 94,\n",
      "       54, 55, 50, 51, 94, 41, 53, 49, 39, 94, 29, 24, 94,  6,  2,  4,  6,\n",
      "        8, 96, 56, 53, 42, 40, 49, 55, 75, 94, 44, 22, 25, 24, 27, 29, 10,\n",
      "       23, 29, 94, 18, 23, 15, 24, 27, 22, 10, 29, 18, 24, 23, 94, 15, 24,\n",
      "       27, 94,  0,  2, 94, 30, 28, 14, 27, 75, 94, 55, 24, 13, 10, 34, 94,\n",
      "       18, 28, 94, 34, 24, 30, 27, 94, 21, 30, 12, 20, 34, 94, 13, 10, 34,\n",
      "       62, 94,  2, 94, 15, 18, 23, 13, 94, 24, 30, 29, 94, 32, 17, 34, 94,\n",
      "       73, 94, 21, 24, 16, 94, 24, 23, 29, 24, 94, 17, 29])>, <tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([11, 14, 94, 17, 14, 27, 94, 15, 27, 18, 14, 23, 13, 75, 94, 53, 14,\n",
      "       25, 21, 34, 94, 60, 40, 54, 74,  4,  4,  0, 94, 24, 27, 94, 49, 50,\n",
      "       74,  4,  4,  0, 94, 54, 14, 14, 94, 17, 14, 27, 77, 94, 32, 32, 32,\n",
      "       75, 54, 48, 54, 75, 10, 12, 76, 30, 76, 23, 10, 29,  2,  7,  0,  8,\n",
      "        1,  9,  8,  0, 94, 54, 55, 50, 51, 82, 94, 54, 14, 23, 13, 94, 54,\n",
      "       55, 50, 51, 94, 41, 53, 49, 39, 94, 29, 24, 94,  6,  2,  4,  6,  8,\n",
      "       96, 56, 53, 42, 40, 49, 55, 75, 94, 44, 22, 25, 24, 27, 29, 10, 23,\n",
      "       29, 94, 18, 23, 15, 24, 27, 22, 10, 29, 18, 24, 23, 94, 15, 24, 27,\n",
      "       94,  0,  2, 94, 30, 28, 14, 27, 75, 94, 55, 24, 13, 10, 34, 94, 18,\n",
      "       28, 94, 34, 24, 30, 27, 94, 21, 30, 12, 20, 34, 94, 13, 10, 34, 62,\n",
      "       94,  2, 94, 15, 18, 23, 13, 94, 24, 30, 29, 94, 32, 17, 34, 94, 73,\n",
      "       94, 21, 24, 16, 94, 24, 23, 29, 24, 94, 17, 29, 29])>)\n"
     ]
    }
   ],
   "source": [
    "with open('./spam.txt', 'r', encoding=\"UTF8\") as f:\n",
    "    textfile = f.read()\n",
    "\n",
    "TEXT_LENGTH = len(textfile)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "textfile = unidecode.unidecode(textfile)\n",
    "textfile = re.sub(' +',' ', textfile)\n",
    "\n",
    "def pick_input(textfile):\n",
    "    start_index = random.randint(0, TEXT_LENGTH - SEQ_LENGTH)\n",
    "    end_index = start_index + SEQ_LENGTH + 1\n",
    "    return textfile[start_index:end_index]\n",
    "\n",
    "def char2tensor(text):\n",
    "    lst = [string.printable.index(c) for c in text]\n",
    "    tensor = tf.Variable(lst)\n",
    "    return tensor\n",
    "\n",
    "def draw_random_sample(textfile):    \n",
    "    sampled_seq = char2tensor(pick_input(textfile))\n",
    "    inputs = sampled_seq[:-1]\n",
    "    outputs = sampled_seq[1:]\n",
    "    return inputs, outputs\n",
    "\n",
    "print(draw_random_sample(textfile))\n",
    "print(draw_random_sample(textfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Data Preparation Functions\n",
    "You can add any other functions that preparation data in below cell.  \n",
    "\n",
    "However, you should annotate precisely for each functions you define. One annotation line should not cover more than 5 lines that you write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1: RNN/LSTM/GRU Module\n",
    "\n",
    "The main task is to create RNN/LSTM/GRU network. You can use any tensorflow/keras api that basically given.\n",
    "\n",
    "Basically build_model are given, but you can add other functions that help your networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### WRITE DOWN YOUR CODE ################################\n",
    "\n",
    "def build_model(EMBEDDING_DIM, HIDDEN_DIM ):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(100, EMBEDDING_DIM,\n",
    "                              batch_input_shape=[1, None]),\n",
    "    tf.keras.layers.LSTM(256,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(HIDDEN_DIM),\n",
    "    tf.keras.layers.Dense(100)\n",
    "  ])\n",
    "    return model\n",
    "\n",
    "#################### WRITE DOWN YOUR CODE ################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Task: Train & Generate Code\n",
    "\n",
    "These cells would define functions of training network and generating text function. \n",
    "\n",
    "You can change these codes but if then you should annotate where do you make change precisely.\n",
    "One annotation line should not cover more than 5 lines that you make your changes.  \n",
    "Also, do not delete original code, just comment out them. (or make another cells of jupyter notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(EMBEDDING_DIM,HIDDEN_DIM)\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "def accuracy(labels, logits):\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(labels, logits)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() \n",
    "model.compile(optimizer=optimizer, loss=loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  \n",
    "    num_generate = SEQ_LENGTH\n",
    "    input_eval = char2tensor(start_string)\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "    temperature = 0.8\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predictions = tf.math.exp(predictions)\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(string.printable[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Code & Credit Creterion\n",
    "Half Credit (4 points): Generate some ugly text, without any meaningful words.\n",
    "\n",
    "Q3 Credits (6 points): In SEQ_LENGTH 200, generate 6 or less differet words.\n",
    "\n",
    "Full Credit (8 points): in SEQ_LENGTH 200, generate 7 or more different words.\n",
    "\n",
    "\n",
    "\n",
    "You can change this cell based on your code modifications above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './tf-checkpoints'+ datetime.datetime.now().strftime(\"_%Y.%m.%d-%H_%M_%S\") # On Windows, \":\" can't be included in directory or file name, so I changed the ckpt folder name format. \n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_0\")\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0\n",
      "joyQJ)F9\n",
      "\tooA1Wg*Ju75'%--87 /hPUTWe\f",
      "?_5]SS!*)Q/_3-$yxdLj3E6]]Wn\n",
      "P\f",
      "g%#07`|n785%#Hc),vQ[_$uofEM\tTFq. m.Fvcw.:=LZ#\\yM*M(9 Z/WW/3k&95Dm`MAg>d7W}6\"0`LbSyE9bY\n",
      "9bK5f&\n",
      "Iteration 0\n",
      "joyQJ)F9\n",
      "\tooA1Wg*Ju75'%--87 /hPUTWe\f",
      "?_5]SS!*)Q/_3-$yxdLj3E6]]Wn\n",
      "P\f",
      "g%#07`|n785%#Hc),vQ[_$uofEM\tTFq. m.Fvcw.:=LZ#\\yM*M(9 Z/WW/3k&95Dm`MAg>d7W}6\"0`LbSyE9bY\n",
      "\"t.X{sSMS! yQsmC?#)2eLvBp-X?}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1000\n",
      "joyur mobile wor a PS200 are and week mobile wor a PS200 are and week sent mers week sent week to contate to contate to contate to contate to contate to contate to contate to contate to contate to contat\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2000\n",
      "joy ur call 0906666444 from land line. Claim cost 10p per mine call 0906666444 from land line. Claim cost 10p per mine call 0906666444 from land line. Claim cost 10p per mine call 0906666444 from land li\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3000\n",
      "joythe customer service announcement for some any text the 2nd to order to the latest colour camera mins and text to the word our diting the 2nd attempt to our offer of a chance to win a PS250 weekly com\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4000\n",
      "joy the latest from Sanda Ding Prize on 08000 3070 Iccount Statement for shows 800 un-redeemed S. I. M. points. Call 08712400220 (10p/min)\n",
      "FreeMsg: Chard NOW SMEP to 8007 T's&C's www.movietrivia.tv custc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5000\n",
      "joytand your complimentary to your phone! Text YES to 85023 now! SavaMob, member offers mobile! T Cs 0871878880. Good M26 3UZ 150ppm\n",
      "Free entry into our PS250 weekly draw txt MUSIC to 87066 Ts&Cs www.Lde\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6000\n",
      "joy The complimentary 4* Ibiza Holiday or PS5000 cash or a PS2000 prize! Txt word: COLLECT to No: 83355! IBHltd LdnW15H 150p/Mtmsgrcvd18\n",
      "Hi things wkly comp to win FREE to 87066 Ts&Cs www.Ldew.com1win150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7000\n",
      "joy Great Orange customer, you may now chat a stamped a read for camera phones with a FREE sexy pic of Jordan!Txt PIC to 89135 now! 150p/Msg. CC 08718720201 PO BOX135W45WQ 150ppm\n",
      "Free entry 2 100 wkly dr\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8000\n",
      "joy The completent from 150p resubscription sent this is the 2nd attempt to reach YOU! Call 09066362221 ING POBYP 12+ to 83070. T&CsBBX SPOXUW\n",
      "PRIVATE For FUR awarded a SiPix Digital Camera! call 0906122\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9000\n",
      "joy The contact YOU! Call 09066352731 from your landline. Your complimentary 4* Tenerife Holiday or #5000 cash await collection. To claim CALL NOW 09066364321 from landline. Your complimentary 4* Tenerif\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10000\n",
      "joy The contact with U-find out who they R*reveal who thinks UR so special-call on 09065171142-stopsms-08718727870150ppm\n",
      "Mila, age23, blonde, new in UK. I look sex with UK guys. if u like fun with me. Te\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11000\n",
      "joy The conting you do. I want real doggin locations sent direct to your mobile? join the UKs largest dogging network. txt dogs to 69696 now!nyt. ec2a. 3lp PS1.50/msg.\n",
      "U have WON a guaranteed PS1000 cash\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12000\n",
      "joy the top offer of a Video Handset? 750 anytime any network mins Half Price Line Rental That is a $5. Initie 3734 Whan Woldaim backEod? PHARITEnto claim code 733 standard rates app\n",
      "CDs 4u: Congratulati\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13000\n",
      "joy the following link on your prize. 2 claim is easy, just call 08718726978 NOW! Only 10p per minute. BT-national-rate\n",
      "44 7732584351, Do you want a New Nokia 3510i Colour Phone Delivered Tomorrow? With \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14000\n",
      "joy The conthect your PS1000 cash or a 4* holiday (flights inc) speak to a live operator NOW!\n",
      "Hi this is Amy, we will be sending you a free phone number in a couple of days, which you re your reply to ou\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15000\n",
      "joy The compE txt NOKIA to 8077 Get txting and tell ur mates. www.getzed.co.uk POBox 36504 W45WQ 16+ norm150p/tone\n",
      "Gut your game now! txt CHAT to 80878. T's&C's www.AULCHM, SWITAC FREE BAND SERE BUNIS FR\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16000\n",
      "joy the tried to sours to use just got the weekend draw shows that you have won a PS2000 prize GUARANTEED. Call 09066368323 ASAP! Box 97N7QP, 150ppm\n",
      "Double your mins & txts on Orange tariffs. Latest Moto\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17000\n",
      "joy The conthert you have been selected to receive a PS400 prize GUARANTEED. Call 09066660970 NOW\n",
      "He wor tried 2 contact u. U have won the PS400 prize. 2 claim is easy, just call 08719180248 Identifier C\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18000\n",
      "joy the the weekend's fun. Call 08718726970 NOW! Only 10p per min. BT-national-rate\n",
      "Got who it is, call from a land line 09050000980 from land line. Valid 12hrs only\n",
      "YES! The only place in town to meet e\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19000\n",
      "joy the followion of selected to stay in 1 of 250 top British hotels - FOR NOTHING! Holiday valued at PS5000. To stop text stop to stop one next video//22mands un your partner on the trip of a lifetime! \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start Training by running this cell\n",
    "for i in range(N_ITER):\n",
    "    x, y = draw_random_sample(textfile)\n",
    "    history = model.fit(tf.expand_dims(x, 0), tf.expand_dims(y, 0), epochs=1, callbacks=[checkpoint_callback], verbose=0)\n",
    "    if (i % TXT_GEN_PERIOD == 0):\n",
    "            checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_%d\"%i)\n",
    "            checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_prefix,\n",
    "                save_weights_only=True)\n",
    "            print(\"\\nIteration %d\"%i)\n",
    "            print(generate_text(model, 'joy'))\n",
    "            print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading Code\n",
    "You can change this if you don't like or understand this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2799cb853c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(EMBEDDING_DIM,HIDDEN_DIM)\n",
    "model.load_weights('./tf-checkpoints_2020.11.30-15_18_07/ckpt_19000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pre-trained Networks: Transformers\n",
    "\n",
    "Actually, RNN-based sequential model is now regarded as little bit old-fashioned, since 'Transformer' model was announced in paper 'Attention is All You Need'(https://arxiv.org/abs/1706.03762). Now this model is widely used on many state-of-the-art sequential-data-use model, and even in non-sequential-data-use (ex)image) model too. However, model training cost is too heavy(maybe you need multiple million-won GPUs) to train on this homework. Fortunately, there is package called 'transformers' that contains multipe pre-trained transformer-based model that can be used directly. Below is example of text generation using GPT2, which is one of the most popular pre-trained NLP models.\n",
    "\n",
    "You can install this package with 'pip install transformers'. To download pre-traind model, you may have 2GB or more free disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Newton was indeed sitting under an apple tree, in front of a long bar with its own mirror.\\n\\n\"Hey, there\\'s that apple too, I\\'ll get in for more help. It has something called a \"Cadillac-Style,\" or whatever you prefer—it has two sides, and the top was built from that apple and there\\'s other stuff like this one.\"\\n\\nThere was a man in his late twenties holding a sign to his wife.\\n\\nHe was just waiting for her to pull out the newspaper and read the news, and then went downstairs first thing. He wanted to know what was the issue, so he started thinking of a way to help. His wife kept saying, \"Did you get a Cadillac.\" And here he was, with a long white hair and a blue shirt with a gold trim with a little red crown, in front of a mirror, in an old car with a small window, with a big red button down.\\n\\nHe got out—washed it down, let his wife know that it was over, opened the window and looked up at the red screen.\\n\\nShe was right. He went upstairs to start reading another newspaper, looking out to the side. A couple of guys in big T-shirts and polo shirts went under the window, and they all got out and began talking to the same little girl with a black leather jacket. The girl with the jacket wasn\\'t the sort of girl who was'},\n",
       " {'generated_text': 'Newton was indeed sitting under an apple tree on March 12, 1981. During the holiday period on Long Island, she took a taxi to Union Station and stayed at the Rose Cafe during the night at the Rose\\'s Café.\\n\\nShe would arrive at the restaurant around 3:30 a.m. while it was still serving chicken and fries.\\n\\nIt\\'s not entirely clear what occurred during that time frame.\\n\\nIn a statement prepared by the Rose Cafe on the March 12, 1981 list of dates for the return of her car, the restaurant stated that \"at 9:45 A.M., a waitress called and said, \\'She works as a waitress at Union Station, as her schedule doesn\\'t allow her to work at the restaurant.\\' The response was, \\'Hey, I don\\'t see why she would be willing to work at [Union Station], but we think they gave her time.\\'\"\\n\\nAlthough McDonald\\'s does not have a location in New York City at those times, the Rose said the restaurant does offer free lunch to workers in the area and for guests in New York City.\\n\\nAccording to the Rose, McDonald\\'s is also open on Sundays from 11 a.m.- 8 p.m., the day after Labor Day of 1983, according to the Rose.\\n\\nThe restaurant also does offer free food, free pizza and free pizza packages delivered at 9 a.m. in New York City on Saturday mornings. All of these meals are provided by the'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "# Install ipywidgets and restart notebooks if you meet error message.\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(25)\n",
    "start_text = 'Newton was indeed sitting under an apple tree'\n",
    "generator(start_text, max_length=300, num_return_sequences=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2: Follow Tutorial of Fine-tuned Networks (2 points.)\n",
    "There are hundreds of fine-tuned NLP models in 'transformers' package. Try one of these models and follow its tutorial (except language translation model). Results must produce some meaningful, or funny one, and you must write down what model you choose and explain its function (ex) what is input/output, what does it mean etc) with one or two sentences. \n",
    "\n",
    "Hint: You can find list of pre-trained models in 'transformers' package on https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': '[CLS] newton grabbed the phone and had the eureka moment. [SEP]',\n",
       "  'score': 0.06330826133489609,\n",
       "  'token': 3042,\n",
       "  'token_str': 'phone'},\n",
       " {'sequence': '[CLS] newton grabbed the remote and had the eureka moment. [SEP]',\n",
       "  'score': 0.03353388234972954,\n",
       "  'token': 6556,\n",
       "  'token_str': 'remote'},\n",
       " {'sequence': '[CLS] newton grabbed the keys and had the eureka moment. [SEP]',\n",
       "  'score': 0.022189976647496223,\n",
       "  'token': 6309,\n",
       "  'token_str': 'keys'},\n",
       " {'sequence': '[CLS] newton grabbed the wheel and had the eureka moment. [SEP]',\n",
       "  'score': 0.02009352296590805,\n",
       "  'token': 5217,\n",
       "  'token_str': 'wheel'},\n",
       " {'sequence': '[CLS] newton grabbed the ball and had the eureka moment. [SEP]',\n",
       "  'score': 0.01614222675561905,\n",
       "  'token': 3608,\n",
       "  'token_str': 'ball'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################### WRITE DOWN YOUR CODE ################################\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "unmasker(\"Newton grabbed the [MASK] and had the Eureka moment.\")\n",
    "\n",
    "\n",
    "#################### WRITE DOWN YOUR CODE ################################\n",
    "\n",
    "########### WRITE DOWN YOUR Explaination with annotation #################\n",
    "\n",
    "# Explaination: BERT는 [MASK]로 표시된 빈칸을 유추하는 모델로, 빈칸이 하나 포함된 문장이 INPUT으로 주어지면 그에 대한 OUTPUT으로 빈칸에\n",
    "# 들어갈 단어를 유추한다. 이 예시의 경우 뉴턴이 사과를 집어들고서 중력에 대한 깨달음을 얻었다 라는 문장을 유추하고자 했는데,\n",
    "# 가장 SCORE가 높은 것이 PHONE으로 나왔다. 그 시대에는 PHONE이 없을 뿐더러 뭔가 APPLE과 PHONE사이의 묘한 관계가 재미있어서 이러한 예시로 골랐다.\n",
    "\n",
    "##########################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Information: Project\n",
    "Of course, there are massive ammount of pretrained models on domain of image, NLP or else in web with open-source licenses. You can fine-tune those models if your GPUs are good enough, or at least transfer its information by using output feature of pre-trained networks. Or, maybe neither, it is up to you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
